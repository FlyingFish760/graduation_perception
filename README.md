# Prescan Traffic Sign Detection

This repository contains the end-to-end workflow to build a traffic sign detector from Prescan simulation data, which is used in the graduation project "Linear Temporal Logic-based risk-aware autonomous driving with perception in Prescan framework". It covers converting the original Prescan data to the YOLO format, curating train/validation splits, and fine-tuning a Ultralytics YOLO model.

## Repository Layout
- `create_dataset.ipynb` converts the Prescan `ground_truth.mat` annotations into YOLO label files and optionally downsamples frames using frame skipping.
- `create_train_val_dataset.ipynb` builds the train/validation split in the structure expected by Ultralytics.
- `train_val_model.ipynb` fine-tunes a YOLO model using the curated dataset.
- `utils_own.py` helper functions for coordinate conversions and dataset utilities.
- `AMC_demo_data/` raw Prescan export with camera frames and the original `.mat` annotations.
- `AMC_demo_data_new_dataset/` frame-skipped subset generated by `create_dataset.ipynb`.
- `AMC_train_val_dataset/` YOLO-formatted dataset (train/val folders plus `prescan.yaml`).
- `yolo11n.pt`, `yolo11s.pt` pretrained checkpoints used as starting points for training.

## Prerequisites
- Python 3.10+
- Recommended packages:
  - `numpy`
  - `scipy`
  - `opencv-python`
  - `ultralytics`
  - `matplotlib` (for optional visual checks)
- A GPU with CUDA support is strongly recommended for training.

Create and activate a virtual environment, then install what you need with for example:
```bash
python -m venv .venv
source .venv/bin/activate        # On Windows: .venv\Scripts\Activate.ps1
pip install ultralytics scipy opencv-python matplotlib
```

## Workflow

### 1. Generate YOLO labels and optional frame skipping (`create_dataset.ipynb`)
- Reads the `.mat` file, maps Prescan object IDs to four YOLO classes (traffic signal, speed limit 20/30/50), and writes per-frame label files under `AMC_demo_data/labels/`.
- Renames the images so they share the same stem as their label files.
- Optionally creates the downsampled dataset `AMC_demo_data_new_dataset/` by copying every *n*th frame (`num_frame_skip`).
- You can tweak:
  - `numid_to_classid` to change class mappings.
  - `num_frame_skip` to control how aggressively frames are sampled.

### 2. Create train/validation split (`create_yolo_format_dataset.ipynb`)
<!-- - Shuffles the images in `AMC_demo_data_new_dataset/` (set via `dataset_dir`).
- Copies them into `AMC_train_val_dataset/train|val/(images|labels)` according to `train_ratio`.
- The generated layout satisfies Ultralytics' expectations. -->

### 3. Train a YOLO detector (`train_val_model.ipynb`)
<!-- - Loads a pretrained checkpoint (default `yolo11s.pt`).
- Points the trainer to `AMC_train_val_dataset/prescan.yaml`.
- Trains for 50 epochs with custom augmentation and optimization settings. -->
- Adjust `epochs`, `batch`, `device`, and augmentation knobs to fit your hardware and dataset size.

To run training outside the notebook you can execute the equivalent script:
```python
from ultralytics import YOLO

model = YOLO("yolo11s.pt")
model.train(
    data="AMC_train_val_dataset/prescan.yaml",
    epochs=50,
    batch=0.6,
    device="0",
    weight_decay=0.001,
    hsv_s=0.8,
    degrees=5,
    translate=0.1,
    scale=0.2,
    fliplr=0.5,
)
```

<!-- ### 5. Evaluate and export
- By default Ultralytics writes results and checkpoints under `runs/detect/`.
- Use `model.val(data=...)` or the notebook widgets to inspect metrics and confusion matrices.
- For inference on new frames:
```python
model = YOLO("runs/detect/train/weights/best.pt")
results = model.predict("path/to/images", conf=0.25)
``` -->

## Dataset configuration
`AMC_train_val_dataset/prescan.yaml` defines the dataset root and four class names:
```yaml
train: ../train
val: ../val
names:
  0: traffic signal
  1: speed limit 20
  2: speed limit 30
  3: speed limit 50
```
Update `names` if you change the mapping in `create_dataset.ipynb`.

<!-- ## Troubleshooting & tips
- If `scipy.io.loadmat` cannot open the file, verify the `.mat` version and that `data_folder` points to the right directory.
- The notebooks delete and recreate label directories; back up your data if you made manual edits.
- Keep the image and label counts identical before running the train/val split to avoid missing label errors.
- Tune `train_ratio` or extend the script to create a test split if needed.
- Monitor GPU memory usage; lower `batch` or image size if you encounter out-of-memory errors.

## Credit
Utilities in `utils_own.py` and the dataset processing notebooks were authored by Jingyuan Han as part of the graduation perception project. -->

## Contact
Jingyuan Han (j.han@student.tue.nl)